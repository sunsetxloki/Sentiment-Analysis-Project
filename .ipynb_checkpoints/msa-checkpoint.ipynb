{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7291d1a8-4e0e-4f6c-8a54-01a226ded88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allei\\Documents\\Movie Sentiment Analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e017929-3425-4067-9b20-98f05852570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the path to the dataset\n",
    "dataset_path = \"aclImdb/\"\n",
    "\n",
    "# Check the contents of the folder\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4563311-f560-4c43-9428-c7e5e04c5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subfolders: ['labeledBow.feat', 'neg', 'pos', 'unsup', 'unsupBow.feat', 'urls_neg.txt', 'urls_pos.txt', 'urls_unsup.txt']\n",
      "Test Subfolders: ['labeledBow.feat', 'neg', 'pos', 'urls_neg.txt', 'urls_pos.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "train_path = \"aclImdb/train\"\n",
    "test_path = \"aclImdb/test\"\n",
    "\n",
    "# Check subfolders\n",
    "print(\"Train Subfolders:\", os.listdir(train_path))\n",
    "print(\"Test Subfolders:\", os.listdir(test_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb63525-4b2d-4c3b-8eaf-ed328881af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...  positive\n",
      "1  Homelessness (or Houselessness as George Carli...  positive\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...  positive\n",
      "3  This is easily the most underrated film inn th...  positive\n",
      "4  This is not the typical Mel Brooks film. It wa...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load reviews\n",
    "def load_reviews(directory, sentiment):\n",
    "    reviews = []\n",
    "    folder = os.path.join(directory, sentiment)\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), encoding=\"utf-8\") as file:\n",
    "            reviews.append(file.read())\n",
    "    return reviews\n",
    "\n",
    "# Load train data\n",
    "pos_reviews = load_reviews(train_path, \"pos\")\n",
    "neg_reviews = load_reviews(train_path, \"neg\")\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"review\": pos_reviews + neg_reviews,\n",
    "    \"sentiment\": [\"positive\"] * len(pos_reviews) + [\"negative\"] * len(neg_reviews)\n",
    "})\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10b04d5c-3634-417a-bb20-3f167e2f6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns of the dataset\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f99723d-61a3-4edd-b46b-d4b3d81b3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('IMDB Dataset'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f856cbca-96e8-4f4e-b951-3f0d7121d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labeledBow.feat', 'neg', 'pos', 'unsup', 'unsupBow.feat', 'urls_neg.txt', 'urls_pos.txt', 'urls_unsup.txt']\n",
      "['labeledBow.feat', 'neg', 'pos', 'urls_neg.txt', 'urls_pos.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('IMDB Dataset/train'))\n",
    "print(os.listdir('IMDB Dataset/test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2776a49b-725f-43a4-b2f5-7b9629a95711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...          1\n",
      "1  Homelessness (or Houselessness as George Carli...          1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...          1\n",
      "3  This is easily the most underrated film inn th...          1\n",
      "4  This is not the typical Mel Brooks film. It wa...          1\n",
      "                                              review  sentiment\n",
      "0  I went and saw this movie last night after bei...          1\n",
      "1  Actor turned director Bill Paxton follows up h...          1\n",
      "2  As a recreational golfer with some knowledge o...          1\n",
      "3  I saw this film in a sneak preview, and it is ...          1\n",
      "4  Bill Paxton has taken the true story of the 19...          1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read reviews from a folder (positive or negative)\n",
    "def load_reviews_from_folder(folder, sentiment):\n",
    "    reviews = []\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file:\n",
    "            reviews.append((file.read(), sentiment))\n",
    "    return reviews\n",
    "\n",
    "# Path to the 'train' directory\n",
    "train_pos_dir = 'IMDB Dataset/train/pos'\n",
    "train_neg_dir = 'IMDB Dataset/train/neg'\n",
    "\n",
    "# Load positive and negative reviews for training\n",
    "positive_reviews_train = load_reviews_from_folder(train_pos_dir, 1)  # 1 for positive sentiment\n",
    "negative_reviews_train = load_reviews_from_folder(train_neg_dir, 0)  # 0 for negative sentiment\n",
    "\n",
    "# Combine the reviews and their labels\n",
    "train_reviews = positive_reviews_train + negative_reviews_train\n",
    "\n",
    "# Convert to a DataFrame for easier manipulation\n",
    "train_data = pd.DataFrame(train_reviews, columns=['review', 'sentiment'])\n",
    "\n",
    "# Check the first few rows of the training data\n",
    "print(train_data.head())\n",
    "\n",
    "# Repeat the process for the test set (if needed)\n",
    "test_pos_dir = 'IMDB Dataset/test/pos'\n",
    "test_neg_dir = 'IMDB Dataset/test/neg'\n",
    "\n",
    "positive_reviews_test = load_reviews_from_folder(test_pos_dir, 1)\n",
    "negative_reviews_test = load_reviews_from_folder(test_neg_dir, 0)\n",
    "\n",
    "test_reviews = positive_reviews_test + negative_reviews_test\n",
    "test_data = pd.DataFrame(test_reviews, columns=['review', 'sentiment'])\n",
    "\n",
    "# Check the test data\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "773fc5c1-9d99-4700-9cc2-e2329178cf83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaCy is installed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(\"SpaCy is installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2327d201-08ed-4e56-97fd-b8f29e0bf7bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load Spacy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize stemmer and stopwords\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and tokenize using SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    words = [stemmer.stem(token.text) for token in doc if token.text not in stop_words and not token.is_punct]\n",
    "\n",
    "    # Join the words back into a cleaned-up sentence\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data['cleaned_review'] = train_data['review'].apply(preprocess_text)\n",
    "test_data['cleaned_review'] = test_data['review'].apply(preprocess_text)\n",
    "\n",
    "# Check the cleaned data\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a7323-6f50-4f40-a53d-4b315cad1fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
